# Interview Prep AI - Complete End-to-End Project Understanding

**Last Updated:** February 23, 2026  
**Project Type:** Full-Stack Web Application  
**Technology Stack:** Python/FastAPI Backend + Next.js/TypeScript Frontend + PostgreSQL

---

## ğŸ“‹ Executive Summary

**Interview Prep AI** is a full-stack mock interview platform that helps candidates practice technical and behavioral interviews with AI-driven follow-ups and comprehensive scoring. The system uses DeepSeek LLM for intelligent interviewing with fallback mechanisms, comprehensive session tracking, and rubric-based evaluation.

**Key Value Proposition:**

- Realistic interview simulation with adaptive difficulty
- AI-powered dynamic follow-ups
- Comprehensive performance analytics
- Local deployment with PostgreSQL backend
- JWT authentication with email verification

---

## ğŸ—ï¸ System Architecture Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         User Browser                             â”‚
â”‚                    (Next.js Frontend App)                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Pages: Login, Signup, Dashboard, Interview, Results      â”‚   â”‚
â”‚  â”‚ Components: ChatUI, QuestionDisplay, Timer, Analytics    â”‚   â”‚
â”‚  â”‚ State: Zustand (auth, session, UI)                       â”‚   â”‚
â”‚  â”‚ API Client: Axios with token interceptor                 â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚ HTTPS/HTTPS
                        â”‚ Bearer Token Auth
                        â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              FastAPI Backend (Python)                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ /api/v1/                                                 â”‚   â”‚
â”‚  â”‚  â”œâ”€ auth/ (signup, login, verify, password-reset)       â”‚   â”‚
â”‚  â”‚  â”œâ”€ sessions/ (CRUD, messages, finalize)                â”‚   â”‚
â”‚  â”‚  â”œâ”€ questions/ (retrieve by ID)                          â”‚   â”‚
â”‚  â”‚  â”œâ”€ analytics/ (performance, results)                    â”‚   â”‚
â”‚  â”‚  â”œâ”€ ai/ (LLM status)                                     â”‚   â”‚
â”‚  â”‚  â”œâ”€ voice/ (TTS generation)                              â”‚   â”‚
â”‚  â”‚  â””â”€ users/ (profile management)                          â”‚   â”‚
â”‚  â”‚                                                           â”‚   â”‚
â”‚  â”‚ Core Services:                                            â”‚   â”‚
â”‚  â”‚  â”œâ”€ InterviewEngine: Question selection, flow control    â”‚   â”‚
â”‚  â”‚  â”œâ”€ ScoringEngine: Evaluation & rubric scoring           â”‚   â”‚
â”‚  â”‚  â”œâ”€ DeepSeekClient: LLM API integration                  â”‚   â”‚
â”‚  â”‚  â”œâ”€ TTS Service: Audio generation                        â”‚   â”‚
â”‚  â”‚  â””â”€ RAG Service: Semantic knowledge base                 â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚ SQL Queries
                        â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         PostgreSQL Database (Docker Container)                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Tables:                                                   â”‚   â”‚
â”‚  â”‚  â”œâ”€ users: Authentication & profiles                     â”‚   â”‚
â”‚  â”‚  â”œâ”€ interview_sessions: Session metadata & state         â”‚   â”‚
â”‚  â”‚  â”œâ”€ questions: Question bank                             â”‚   â”‚
â”‚  â”‚  â”œâ”€ messages: Chat history                               â”‚   â”‚
â”‚  â”‚  â”œâ”€ evaluations: Scoring & rubrics                       â”‚   â”‚
â”‚  â”‚  â”œâ”€ session_questions: Sessionâ†’Question mapping          â”‚   â”‚
â”‚  â”‚  â”œâ”€ session_feedback: User ratings                       â”‚   â”‚
â”‚  â”‚  â””â”€ (more: embeddings, audit_log, etc)                  â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”Œ Technology Stack Details

### Backend (Python/FastAPI)

- **Framework:** FastAPI 0.115.6 (async Python web framework)
- **Database:** PostgreSQL 16 + SQLAlchemy 2.0 ORM + Alembic migrations
- **Async Runtime:** Uvicorn 0.34.0
- **Authentication:** PyJWT + Argon2 password hashing
- **LLM Integration:** DeepSeek API via httpx (async HTTP client)
- **Text-to-Speech:** ElevenLabs + custom fallback
- **Embeddings:** Sentence-transformers (for RAG/semantic search)
- **Email:** SMTP support (SendGrid or custom)
- **Testing:** Pytest + pytest-asyncio
- **Code Quality:** Black, Ruff, MyPy

### Frontend (Next.js/TypeScript)

- **Framework:** Next.js 16.1.6 with React 19.2.3
- **Language:** TypeScript 5
- **State Management:** Zustand 5.0.11 (lightweight Jotai alternative)
- **HTTP Client:** Axios 1.13.4 with interceptors
- **API Query:** TanStack React Query 5.90.20
- **Styling:** Tailwind CSS 3.4.17
- **Testing:** Vitest 4.0.18 + React Testing Library
- **Build Tool:** Next.js built-in (Webpack)

### Infrastructure

- **Containerization:** Docker + Docker Compose
- **Database Container:** PostgreSQL:16
- **Port Mapping:** Backend (8000), Frontend (3000), DB (5432)

---

## ğŸ”„ Core Data Models & Relationships

### User Model

```python
- id (PK)
- email (unique, indexed)
- full_name
- role_pref (e.g., "SWE Intern")
- profile (JSON - preferences)
- password_hash
- is_verified
- verification_token
- reset_token
- created_at
```

### InterviewSession Model

```python
- id (PK)
- user_id (FK â†’ User)
- role, track, company_style, difficulty
- difficulty_current (adaptive)
- stage (intro|question|followups|evaluation|done)
- questions_asked_count
- followups_used
- max_questions (default: 7)
- max_followups_per_question (default: 2)
- behavioral_questions_target (default: 2)
- skill_state (JSON - running rubric scores)
- current_question_id
- created_at
```

### Question Model

```python
- id (PK)
- track (e.g., "swe_intern")
- company_style (e.g., "google")
- difficulty (easy|medium|hard)
- title, prompt (text)
- tags_csv (comma-separated: "arrays,sorting,medium")
- followups (JSON - optional dataset-driven followups)
- question_type (coding|system_design|behavioral|conceptual)
- meta (JSON - additional metadata)
```

### Message Model

```python
- id (PK)
- session_id (FK â†’ InterviewSession)
- role (interviewer|student|system)
- content (text)
- created_at
```

### Evaluation Model

```python
- id (PK)
- session_id (FK â†’ InterviewSession, unique)
- overall_score (0-100)
- rubric (JSON - {communication, problem_solving, correctness, complexity, edge_cases})
- summary (JSON - {strengths, weaknesses, next_steps})
- created_at
```

---

## ğŸ¯ Interview Flow - Complete End-to-End Workflow

### 1. User Authentication (Session Initiation)

**Frontend:**

```
User types email/password â†’ Click "Sign Up"
â†“
POST /api/v1/auth/signup
â†“
Backend creates pending_signup row, sends verification code
â†“
Frontend enters 6-digit code â†’ Click "Verify"
â†“
POST /api/v1/auth/verify
â†“
Backend creates User, returns JWT token
â†“
Frontend stores token in localStorage, redirects to dashboard
```

**Backend auth flow:**

- `hash_password()` - Argon2 hashing for storage
- `create_access_token()` - JWT creation with email claim
- Rate limiting on signup (6 calls/min per IP+email)
- Email verification code sent via SMTP or logged to console

### 2. Session Creation & Configuration

**Frontend:**

```
User selects role, track, company, difficulty
â†“
POST /api/v1/sessions
  {
    "track": "swe_intern",
    "company_style": "google",
    "difficulty": "medium",
    "behavioral_questions_target": 2
  }
â†“
Backend validates inputs, creates InterviewSession row
â†“
Response: SessionOut with session.id
```

**Backend:**

- `_validate_session_inputs()` - Validates against ALLOWED_TRACKS, etc.
- Creates session with `stage=intro` and `difficulty_current=easy` (adaptive)
- Sets up skill_state tracking structure

### 3. Warmup Phase (First Message)

**Frontend:**

```
POST /api/v1/sessions/{id}/start
â†“
Backend generates warmup greeting
â†“
Response: First interviewer message
```

**Backend (InterviewEngine.warmup_greeting):**

- Creates personalized interviewer profile (name, gender, company style)
- Returns greeting: "Hi, I'm [Name]. I work at [Company]. How are you?"
- Stores interviewer profile in session.skill_state
- Updates stage to "question"

**Example Output:**

```
"Hi, I'm Sarah, and I'll be your interviewer from Google today.
Let's get started! How are you doing?"
```

### 4. Main Interview Loop (Question & Answer)

**Iteration (5-7 questions typically):**

#### Step 4a: Get Current Question

```
Backend InterviewEngine picks next question:
1. Determine pool: questions matching track/company/current_difficulty
2. Filter by already_seen (UserQuestionSeen)
3. Apply tag diversity: prefer new tags, avoid duplicates
4. Select behavioral vs technical based on target
5. Return question to frontend
```

**Question Selection Algorithm:**

- **Difficulty Adaptation:** Start easy, adjust based on performance
- **Tag Diversity:** Track tags_seen, prefer new domains
- **Behavioral Mix:** Track behavioral_questions_asked vs target
- **Company Style:** Match company_style (google, apple, general)

#### Step 4b: User Answers

```
Frontend:
User types/speaks answer â†’ Click "Send"
â†“
POST /api/v1/sessions/{id}/message
  {
    "input_mode": "text|voice|code",
    "content": "I would use a HashMap..."
  }
â†“
Backend:
1. Quick rubric score user response (0-10 on each dimension)
2. Update skill_state running average
3. Call LLM to generate AI follow-up (or use fallback)
4. Return AI message
â†“
Frontend renders AI message in chat
```

**Backend Processing (POST /sessions/{id}/message):**

1. **Input Validation:**
   - Trim & check length (max 5000 chars)
   - Handle code blocks, voice transcription

2. **Quick Rubric Scoring:**
   - LLM or heuristic scores: communication, problem_solving, correctness, complexity, edge_cases
   - Each 0-10, clamped
   - Example: `{"communication": 7, "problem_solving": 6, ...}`

3. **Skill State Tracking:**

   ```json
   skill_state: {
     "n": 3,  // number of responses scored
     "sum": {"communication": 20, ...},  // cumulative scores
     "last": {"communication": 6, ...}   // last response scores
   }
   ```

4. **Follow-up Generation:**
   - Check if user said "I don't know" or "move on" â†’ use fallback follow-up
   - Check if response too vague â†’ prompt for detail
   - Check if reanchoring needed (went off topic) â†’ redirect
   - Call LLM with system prompt + context
   - Store follow-up as interviewer message

#### Step 4c: Follow-ups (Max 2 per question)

```
If followups_used < max_followups_per_question:
  User can ask for clarification or request follow-up
  â†“
  Backend generates and stores follow-up message
  â†“
  Next iteration: check if max followups reached

If followups_used >= max or user ready:
  Move to next question
```

### 5. Finalization & Scoring

**When all questions complete (questions_asked_count >= max_questions):**

```
Frontend:
POST /api/v1/sessions/{id}/finalize
â†“
Backend (ScoringEngine):
1. Retrieve all messages (transcript)
2. Detect which questions were asked (from session_questions)
3. Build rubric context (include behavioral rubric if applicable)
4. Optionally retrieve RAG context from similar sessions
5. Call LLM: "Score this interview using the rubric..."
6. Parse response: {overall_score, rubric, strengths, weaknesses, next_steps}
7. Store Evaluation row
8. Trigger embedding generation for future RAG
â†“
Response: Evaluation with score (0-100) + detailed breakdown
```

**Scoring Rubric:**

```json
{
  "overall_score": 72,
  "rubric": {
    "communication": 7,
    "problem_solving": 7,
    "correctness_reasoning": 6,
    "complexity": 8,
    "edge_cases": 5
  },
  "strengths": [
    "Clear explanation of approach",
    "Considered edge cases early",
    "Good communication of tradeoffs"
  ],
  "weaknesses": [
    "Could have optimized space complexity",
    "Didn't discuss follow-up improvements",
    "Minor syntax errors in pseudocode"
  ],
  "next_steps": [
    "Practice space optimization techniques",
    "Work on system design at scale",
    "Review common edge cases in similar problems"
  ]
}
```

### 6. Results & Analytics (Post-Interview)

**Frontend:**

```
GET /api/v1/analytics/sessions/{id}/results
â†“
Backend returns: full evaluation, session metadata, performance trends
â†“
Frontend displays: score, rubric breakdown, feedback, comparison to prior sessions
```

---

## ğŸ“ Project Directory Structure

### Backend Directory (`backend/`)

```
backend/
â”œâ”€â”€ main.py                          # FastAPI app entry point
â”œâ”€â”€ requirements.txt                 # Python dependencies
â”œâ”€â”€ pytest.ini                       # Test configuration
â”œâ”€â”€ alembic.ini                      # Alembic config
â”œâ”€â”€ seed.py                          # Data seeding script
â”œâ”€â”€ create_test_user.py              # Test user creation
â”‚
â”œâ”€â”€ alembic/                         # Database migrations
â”‚   â”œâ”€â”€ env.py                       # Migration environment
â”‚   â”œâ”€â”€ script.py.mako               # Migration template
â”‚   â””â”€â”€ versions/                    # Migration files (*.py)
â”‚
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py                      # FastAPI setup, middleware, lifespan
â”‚   â”‚
â”‚   â”œâ”€â”€ api/v1/
â”‚   â”‚   â”œâ”€â”€ router.py                # Main V1 router
â”‚   â”‚   â”œâ”€â”€ auth.py                  # Authentication endpoints
â”‚   â”‚   â”œâ”€â”€ sessions.py              # Interview session endpoints
â”‚   â”‚   â”œâ”€â”€ questions.py             # Question retrieval endpoints
â”‚   â”‚   â”œâ”€â”€ analytics.py             # Analytics endpoints
â”‚   â”‚   â”œâ”€â”€ ai.py                    # LLM status endpoint
â”‚   â”‚   â”œâ”€â”€ voice.py                 # TTS endpoints
â”‚   â”‚   â”œâ”€â”€ users.py                 # User profile endpoints
â”‚   â”‚   â”œâ”€â”€ feedback.py              # Session feedback endpoints
â”‚   â”‚   â”œâ”€â”€ embeddings.py            # RAG embeddings endpoints
â”‚   â”‚   â””â”€â”€ chat_threads.py          # Chat thread endpoints (future)
â”‚   â”‚
â”‚   â”œâ”€â”€ models/                      # SQLAlchemy models
â”‚   â”‚   â”œâ”€â”€ user.py
â”‚   â”‚   â”œâ”€â”€ interview_session.py
â”‚   â”‚   â”œâ”€â”€ question.py
â”‚   â”‚   â”œâ”€â”€ message.py
â”‚   â”‚   â”œâ”€â”€ evaluation.py
â”‚   â”‚   â”œâ”€â”€ session_question.py
â”‚   â”‚   â”œâ”€â”€ session_feedback.py
â”‚   â”‚   â”œâ”€â”€ session_embedding.py
â”‚   â”‚   â”œâ”€â”€ chat_thread.py
â”‚   â”‚   â”œâ”€â”€ audit_log.py
â”‚   â”‚   â”œâ”€â”€ pending_signup.py
â”‚   â”‚   â”œâ”€â”€ user_question_seen.py
â”‚   â”‚   â””â”€â”€ (others...)
â”‚   â”‚
â”‚   â”œâ”€â”€ schemas/                     # Pydantic request/response models
â”‚   â”‚   â”œâ”€â”€ auth.py
â”‚   â”‚   â”œâ”€â”€ session.py
â”‚   â”‚   â”œâ”€â”€ message.py
â”‚   â”‚   â”œâ”€â”€ question.py
â”‚   â”‚   â”œâ”€â”€ evaluation.py
â”‚   â”‚   â””â”€â”€ (others...)
â”‚   â”‚
â”‚   â”œâ”€â”€ crud/                        # Database CRUD operations
â”‚   â”‚   â”œâ”€â”€ user.py
â”‚   â”‚   â”œâ”€â”€ session.py
â”‚   â”‚   â”œâ”€â”€ question.py
â”‚   â”‚   â”œâ”€â”€ message.py
â”‚   â”‚   â”œâ”€â”€ evaluation.py
â”‚   â”‚   â””â”€â”€ (others...)
â”‚   â”‚
â”‚   â”œâ”€â”€ services/                    # Business logic
â”‚   â”‚   â”œâ”€â”€ interview_engine.py      # Core interview flow & Q selection
â”‚   â”‚   â”œâ”€â”€ interview_warmup.py      # Warmup logic
â”‚   â”‚   â”œâ”€â”€ scoring_engine.py        # Evaluation & scoring
â”‚   â”‚   â”œâ”€â”€ llm_client.py            # DeepSeek API client
â”‚   â”‚   â”œâ”€â”€ llm_schemas.py           # LLM response schemas
â”‚   â”‚   â”œâ”€â”€ prompt_templates.py      # System/user prompts for LLM
â”‚   â”‚   â”œâ”€â”€ rubric_loader.py         # Rubric context building
â”‚   â”‚   â”œâ”€â”€ rag_service.py           # Semantic search service
â”‚   â”‚   â”œâ”€â”€ session_embedder.py      # Embedding generation
â”‚   â”‚   â””â”€â”€ tts/                     # Text-to-speech
â”‚   â”‚       â”œâ”€â”€ tts_service.py
â”‚   â”‚       â”œâ”€â”€ elevenlabs_tts.py
â”‚   â”‚       â””â”€â”€ default_tts.py
â”‚   â”‚
â”‚   â”œâ”€â”€ core/                        # Configuration & utilities
â”‚   â”‚   â”œâ”€â”€ config.py                # Settings (env vars)
â”‚   â”‚   â”œâ”€â”€ security.py              # JWT, hashing, auth logic
â”‚   â”‚   â”œâ”€â”€ email.py                 # Email sending
â”‚   â”‚   â”œâ”€â”€ constants.py             # Constants (allowed tracks, etc)
â”‚   â”‚   â””â”€â”€ exceptions.py
â”‚   â”‚
â”‚   â”œâ”€â”€ db/
â”‚   â”‚   â”œâ”€â”€ base.py                  # SQLAlchemy declarative base
â”‚   â”‚   â”œâ”€â”€ session.py               # Database session management
â”‚   â”‚   â”œâ”€â”€ init_db.py               # Database initialization
â”‚   â”‚   â””â”€â”€ (others...)
â”‚   â”‚
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ audit.py                 # Audit logging
â”‚   â”‚   â””â”€â”€ (others...)
â”‚   â”‚
â”‚   â””â”€â”€ api/deps.py                  # Dependency injection (get_db, get_current_user)
â”‚
â”œâ”€â”€ tests/                           # Pytest test suite
â”‚   â”œâ”€â”€ test_auth.py
â”‚   â”œâ”€â”€ test_sessions.py
â”‚   â”œâ”€â”€ test_interview_engine.py
â”‚   â””â”€â”€ (others...)
â”‚
â”œâ”€â”€ scripts/                         # Utility scripts
â”‚   â”œâ”€â”€ init_migrations.py
â”‚   â”œâ”€â”€ reset_db.py
â”‚   â””â”€â”€ (others...)
â”‚
â””â”€â”€ htmlcov/                         # Coverage reports
```

### Frontend Directory (`frontend-next/`)

```
frontend-next/
â”œâ”€â”€ package.json                     # Dependencies
â”œâ”€â”€ tsconfig.json                    # TypeScript config
â”œâ”€â”€ vitest.config.ts                 # Test config
â”œâ”€â”€ next.config.ts                   # Next.js config
â”œâ”€â”€ tailwind.config.js               # Tailwind config
â”œâ”€â”€ postcss.config.mjs               # PostCSS config
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ app/                         # Next.js App Router
â”‚   â”‚   â”œâ”€â”€ layout.tsx               # Root layout
â”‚   â”‚   â”œâ”€â”€ page.tsx                 # Home/dashboard page
â”‚   â”‚   â”œâ”€â”€ globals.css              # Global styles
â”‚   â”‚   â”œâ”€â”€ favicon.ico
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ login/
â”‚   â”‚   â”‚   â””â”€â”€ page.tsx             # Login page
â”‚   â”‚   â”œâ”€â”€ signup/
â”‚   â”‚   â”‚   â””â”€â”€ page.tsx             # Signup page
â”‚   â”‚   â”œâ”€â”€ verify/
â”‚   â”‚   â”‚   â””â”€â”€ page.tsx             # Email verification page
â”‚   â”‚   â”œâ”€â”€ forgot-password/
â”‚   â”‚   â”œâ”€â”€ reset-password/
â”‚   â”‚   â””â”€â”€ (other pages...)
â”‚   â”‚
â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”œâ”€â”€ layout/                  # Layout components
â”‚   â”‚   â”‚   â”œâ”€â”€ Header.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ Sidebar.tsx
â”‚   â”‚   â”‚   â””â”€â”€ (others...)
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ sections/                # Full-page sections
â”‚   â”‚   â”‚   â”œâ”€â”€ DashboardSection.tsx # Session list & creation
â”‚   â”‚   â”‚   â”œâ”€â”€ InterviewSection.tsx # Main interview UI
â”‚   â”‚   â”‚   â”œâ”€â”€ ChatSection.tsx      # Chat message display
â”‚   â”‚   â”‚   â”œâ”€â”€ ResultsSection.tsx   # Post-interview results
â”‚   â”‚   â”‚   â”œâ”€â”€ HistorySection.tsx   # Session history
â”‚   â”‚   â”‚   â”œâ”€â”€ PerformanceSection.tsx # Analytics
â”‚   â”‚   â”‚   â””â”€â”€ (others...)
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ modals/
â”‚   â”‚   â”‚   â”œâ”€â”€ CreateSessionModal.tsx
â”‚   â”‚   â”‚   â””â”€â”€ (others...)
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ ui/                      # Reusable UI components
â”‚   â”‚   â”‚   â”œâ”€â”€ Button.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ Input.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ Card.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ Toast.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ Spinner.tsx
â”‚   â”‚   â”‚   â””â”€â”€ (others...)
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ providers/
â”‚   â”‚   â”‚   â””â”€â”€ Providers.tsx        # App-level providers (Zustand, Query)
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ (other components...)
â”‚   â”‚
â”‚   â”œâ”€â”€ lib/
â”‚   â”‚   â”œâ”€â”€ api.ts                   # Axios instance & base API client
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”‚   â”œâ”€â”€ authService.ts       # Auth API calls
â”‚   â”‚   â”‚   â”œâ”€â”€ sessionService.ts    # Session API calls
â”‚   â”‚   â”‚   â”œâ”€â”€ questionService.ts   # Question API calls
â”‚   â”‚   â”‚   â”œâ”€â”€ chatService.ts       # Chat/message API calls
â”‚   â”‚   â”‚   â”œâ”€â”€ analyticsService.ts  # Analytics API calls
â”‚   â”‚   â”‚   â””â”€â”€ aiService.ts         # AI status API calls
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ stores/
â”‚   â”‚   â”‚   â”œâ”€â”€ authStore.ts         # Zustand: Auth state
â”‚   â”‚   â”‚   â”œâ”€â”€ sessionStore.ts      # Zustand: Interview session state
â”‚   â”‚   â”‚   â””â”€â”€ uiStore.ts           # Zustand: UI state (modals, toasts)
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ hooks/
â”‚   â”‚   â”‚   â”œâ”€â”€ useAuth.ts           # Auth context hook
â”‚   â”‚   â”‚   â”œâ”€â”€ useSession.ts        # Session context hook
â”‚   â”‚   â”‚   â””â”€â”€ (others...)
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ utils/
â”‚   â”‚       â”œâ”€â”€ formatters.ts        # Date, number formatting
â”‚   â”‚       â””â”€â”€ (others...)
â”‚   â”‚
â”‚   â”œâ”€â”€ types/
â”‚   â”‚   â”œâ”€â”€ api.ts                   # API request/response types
â”‚   â”‚   â”œâ”€â”€ session.ts               # Session-related types
â”‚   â”‚   â””â”€â”€ (others...)
â”‚   â”‚
â”‚   â”œâ”€â”€ __tests__/
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â””â”€â”€ lib/
â”‚   â”‚
â”‚   â””â”€â”€ public/                      # Static assets
â”‚       â”œâ”€â”€ (icons, images, etc)
â”‚
â””â”€â”€ .env.local                       # Local environment variables
```

### Data Directory (`data/`)

```
data/
â”œâ”€â”€ questions/
â”‚   â”œâ”€â”€ swe_intern/
â”‚   â”‚   â”œâ”€â”€ behavioral.json
â”‚   â”‚   â”œâ”€â”€ coding_easy.json
â”‚   â”‚   â”œâ”€â”€ coding_medium.json
â”‚   â”‚   â”œâ”€â”€ coding_hard.json
â”‚   â”‚   â””â”€â”€ (other categories)
â”‚   â”‚
â”‚   â”œâ”€â”€ swe_engineer/
â”‚   â”œâ”€â”€ data_science/
â”‚   â”œâ”€â”€ devops_cloud/
â”‚   â”œâ”€â”€ product_management/
â”‚   â”œâ”€â”€ cybersecurity/
â”‚   â””â”€â”€ (other tracks...)
â”‚
â””â”€â”€ rubrics/
    â”œâ”€â”€ behavioral_rubric.json
    â”œâ”€â”€ technical_rubric.json
    â””â”€â”€ (other rubric definitions)
```

---

## ğŸ” Authentication & Security Flow

### Signup Process

```
1. User submits email + password + name
   â†“
2. Backend generates 6-digit verification code, stores in pending_signup
   â†“
3. Email sent (or logged to console if SMTP unavailable)
   â†“
4. User enters code in verification form
   â†“
5. Backend validates code, creates User row, marks is_verified=True
   â†“
6. JWT token generated and returned
   â†“
7. Frontend stores token in localStorage["access_token"]
```

### Request Authentication

```
Frontend sends every API request with:
  Authorization: Bearer <JWT_TOKEN>
  â†“
Backend (get_current_user dependency):
  1. Extract token from header
  2. Decode JWT using SECRET_KEY
  3. Extract email from payload
  4. Query User by email
  5. Attach User to request context
  â†“
If token invalid/expired: 401 Unauthorized
If user not found: 401 Unauthorized
```

### Token Structure

```
JWT Payload: {
  "sub": "user@example.com",
  "exp": 1234567890,
  "iat": 1234567000
}
```

---

## ğŸ“Š Key Backend Services

### InterviewEngine (interview_engine.py)

**Responsibilities:**

- Question selection algorithm (adaptive difficulty, tag diversity)
- Warmup greeting generation
- Follow-up generation (LLM or fallback)
- Conversational quality rules (handle "move on", vague answers, off-topic)
- Running skill state tracking

**Key Methods:**

- `warmup_greeting(session)` â†’ First AI message
- `pick_next_question(db, session)` â†’ Select next question
- `generate_ai_response(db, session, user_message)` â†’ Full LLM response + follow-up
- `should_prompt_for_detail(message)` â†’ Detect vague answers
- `_update_skill_state(db, session, scores)` â†’ Track running averages

**Fallback Mechanisms:**

- If DeepSeek unavailable: Use deterministic follow-ups from question.followups JSON
- If no LLM response: Return conservative follow-ups like "Can you elaborate?"
- If skill_state unavailable: Default to "easy" difficulty

### ScoringEngine (scoring_engine.py)

**Responsibilities:**

- Transcript compilation from messages
- Rubric context building
- LLM evaluation call
- Score calibration and validation
- Evaluation storage

**Key Methods:**

- `finalize(db, session_id)` â†’ Async scoring
- `_fallback_evaluation_data()` â†’ Conservative fallback scores
- `_calibrate_overall_score()` â†’ Adjust based on rubric signals

**Output Schema (EvaluationOutput):**

```json
{
  "overall_score": 72,
  "rubric": {
    "communication": 7,
    "problem_solving": 7,
    "correctness_reasoning": 6,
    "complexity": 8,
    "edge_cases": 5
  },
  "strengths": ["..."],
  "weaknesses": ["..."],
  "next_steps": ["..."]
}
```

### DeepSeekClient (llm_client.py)

**Responsibilities:**

- HTTP calls to DeepSeek API
- Retry logic with exponential backoff
- Request/response logging
- Health status tracking
- Error handling and fallback signaling

**Key Methods:**

- `chat(system_prompt, user_prompt, history)` â†’ Text response
- `chat_json(system_prompt, user_prompt)` â†’ JSON response (parsed)
- `_post_with_retries()` â†’ HTTP with retry logic
- Exposed as `/api/v1/ai/status` for frontend badge

### TTS Service (tts/)

**Responsibilities:**

- Audio generation for interview playback
- ElevenLabs API integration with fallback
- Voice selection and caching

**Components:**

- `elevenlabs_tts.py` - Primary TTS provider
- `default_tts.py` - Fallback (gTTS or offline TTS)
- `tts_service.py` - Abstraction layer

---

## ğŸ’¾ Database Design

### Schema Overview

**Core Tables:**

- `users` - User accounts
- `interview_sessions` - Interview instances
- `questions` - Question bank
- `messages` - Chat history
- `evaluations` - Scoring results
- `session_questions` - Sessionâ†’Question mapping
- `user_question_seen` - Track which questions user has seen (prevent repeats)

**Supporting Tables:**

- `session_embedding` - Embeddings for RAG
- `chat_thread` - Multi-turn conversation threads (future)
- `session_feedback` - User ratings/feedback
- `audit_log` - Authentication audit trail
- `pending_signup` - Pending email verification

### Key Indexes

- `users(email)` - Fast login lookup
- `interview_sessions(user_id)` - Fast session listing
- `messages(session_id)` - Fast message retrieval
- `questions(track, company_style, difficulty)` - Fast question selection
- `user_question_seen(user_id, question_id)` - Prevent repeats

### Migrations (Alembic)

- Managed in `backend/alembic/versions/`
- Run `alembic upgrade head` to apply all pending migrations
- Run `alembic revision --autogenerate -m "description"` to create new migrations

---

## ğŸ¬ How to Run Locally

### Prerequisites

- Python 3.10+
- Node.js 18+
- PostgreSQL 13+ (or Docker)

### Backend Setup

```bash
# 1. Navigate to backend
cd backend

# 2. Create virtual environment
python -m venv .venv
source .venv/bin/activate  # Windows: .venv\Scripts\activate

# 3. Install dependencies
pip install -r requirements.txt

# 4. Create .env file (use .env.example as template)
# Set DATABASE_URL, SECRET_KEY, DEEPSEEK_API_KEY (optional)

# 5. Run migrations
alembic upgrade head

# 6. Seed questions (optional)
python seed.py --questions

# 7. Start backend
uvicorn app.main:app --reload
```

Backend will be available at `http://127.0.0.1:8000`

### Frontend Setup

```bash
# 1. Navigate to frontend
cd frontend-next

# 2. Install dependencies
npm install

# 3. Create .env.local
# Set NEXT_PUBLIC_API_URL=http://127.0.0.1:8000/api/v1

# 4. Start dev server
npm run dev
```

Frontend will be available at `http://localhost:3000`

### Database Setup (Docker)

```bash
# From project root
docker-compose up -d

# Creates PostgreSQL container with environment variables from .env
```

---

## ğŸ§ª Testing

### Backend Tests (Pytest)

```bash
cd backend

# Run all tests
pytest

# Run with coverage
pytest --cov=app --cov-report=html

# Run specific test file
pytest tests/test_sessions.py

# Run with verbose output
pytest -v
```

**Test Structure:**

- `tests/test_auth.py` - Authentication endpoints
- `tests/test_sessions.py` - Interview flow
- `tests/test_interview_engine.py` - Question selection
- `tests/test_scoring_engine.py` - Evaluation logic

### Frontend Tests (Vitest)

```bash
cd frontend-next

# Run all tests
npm run test

# Run with watch mode
npm run test

# Run with coverage
npm run test:coverage
```

---

## ğŸ“ˆ Deployment Considerations

### Production Checklist

1. **Environment Variables:**
   - `ENV=production` (disable CORS dev mode)
   - `SECRET_KEY` - Strong random value
   - `DATABASE_URL` - Production PostgreSQL instance
   - `DEEPSEEK_API_KEY` - API key for production
   - SMTP credentials for email

2. **Security:**
   - Enable HTTPS/TLS
   - Set `CORS` to production frontend domain only
   - Use strong database passwords
   - Rotate secrets regularly

3. **Database:**
   - Run migrations on production
   - Set up automated backups
   - Monitor query performance

4. **Monitoring:**
   - Log all errors to centralized logging
   - Monitor API response times
   - Alert on LLM failures

---

## ğŸ”„ State Management

### Frontend State (Zustand)

**AuthStore:**

- `user` - Current authenticated user
- `token` - JWT access token
- `isAuthenticated` - Auth state
- Methods: `login()`, `logout()`, `setUser()`

**SessionStore:**

- `currentSession` - Active interview session
- `messages` - Chat messages
- `evaluation` - Final scoring
- Methods: `createSession()`, `addMessage()`, `finalize()`

**UIStore:**

- `isLoading` - Global loading state
- `toast` - Toast notifications
- `modals` - Modal visibility state
- Methods: `showToast()`, `openModal()`, `closeModal()`

---

## ğŸš€ Key Features & Advanced Flows

### 1. Adaptive Difficulty

- Start at `easy`
- Track running skill scores in `session.skill_state`
- Adjust `difficulty_current` based on performance
- Questions selected from matching difficulty tier

### 2. Tag Diversity

- Track `tags_seen` in skill_state
- Prefer questions with new tags
- Avoid repeated tag combinations
- Ensure coverage across domains

### 3. Behavioral Question Mix

- Target: 2 behavioral questions per session
- Track `behavioral_questions_asked` in skill_state
- Maintain mix even as difficulty increases

### 4. RAG (Retrieval-Augmented Generation)

- After session finalization, generate embeddings
- Store in `session_embedding` table
- Retrieve similar past sessions for scoring context
- Improves evaluation consistency

### 5. Session Embeddings & Knowledge Base

- `session_embedder.py` generates embeddings for:
  - Session transcripts (SessionEmbedding)
  - User responses (ResponseExample)
- Used to find similar past sessions for RAG
- Enables transfer learning across candidates

---

## ğŸ“‹ Important Files Quick Reference

| File                                                         | Purpose              |
| ------------------------------------------------------------ | -------------------- |
| `backend/app/main.py`                                        | FastAPI app setup    |
| `backend/app/services/interview_engine.py`                   | Core interview logic |
| `backend/app/services/scoring_engine.py`                     | Evaluation scoring   |
| `backend/app/services/llm_client.py`                         | LLM integration      |
| `backend/app/api/v1/sessions.py`                             | Session endpoints    |
| `backend/app/models/`                                        | Database models      |
| `frontend-next/src/lib/api.ts`                               | API client           |
| `frontend-next/src/lib/stores/`                              | Zustand state        |
| `frontend-next/src/components/sections/InterviewSection.tsx` | Main interview UI    |
| `data/questions/`                                            | Question datasets    |

---

## ğŸ› Known Limitations & TODO

See `EDGE_CASES_TODO.md` for tracked issues (31 edge cases across 4 phases):

**Phase 1 (Critical - Do First):**

- Finalize race conditions
- Session message locking
- Behavioral target validation

**Phase 2 (High Priority):**

- Message size limits
- Score validation
- Error recovery

**Phase 3 (Medium):**

- Cache optimization
- Database indexing
- Query performance

**Phase 4 (Backlog):**

- Advanced analytics
- Export features
- Integrations

---

## ğŸ“ Key Concepts to Understand

1. **JWT Authentication** - Stateless token-based auth
2. **SQLAlchemy ORM** - Python-to-SQL object mapping
3. **Async/await** - FastAPI async patterns with httpx
4. **Zustand** - Lightweight state management (vs Redux)
5. **LLM Integration** - Prompt engineering + fallback handling
6. **Adaptive Algorithms** - Dynamic difficulty + question selection
7. **RAG (Retrieval-Augmented Generation)** - Context-aware AI responses
8. **Event-Driven Architecture** - Session flows as state machines

---

## ğŸ“ Support & Debugging

### Common Issues

**"Cannot connect to backend"**

- Check backend is running: `uvicorn app.main:app --reload`
- Verify DATABASE_URL and Postgres is running
- Check CORS settings in `backend/app/main.py`

**"Database migrations failed"**

- Run: `alembic upgrade head`
- Check Postgres connection string
- Verify user has permissions

**"LLM responses unavailable"**

- Check DEEPSEEK_API_KEY is set
- Verify DeepSeek API is accessible
- Check `/api/v1/ai/status` endpoint for health

**"Questions not loading"**

- Run: `python seed.py --questions`
- Check questions exist in `data/questions/`
- Verify database migrations have run

---

**This document provides a complete end-to-end understanding of the Interview Prep AI system.**
**For specific implementation details, refer to the source code files listed above.**
